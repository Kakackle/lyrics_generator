{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46714f5a-d924-43b2-a928-5339e7afbb0a",
   "metadata": {},
   "source": [
    "## Basic LSTM rewrite for rease of further experiments\n",
    "\n",
    "still loosely based on:  \n",
    "https://machinelearningmastery.com/text-generation-with-lstm-in-pytorch/\n",
    "\n",
    "but also:  \n",
    "https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/10_time_series_forecasting_in_tensorflow.ipynb\n",
    "\n",
    "and some:  \n",
    "https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896c720c-5453-4ee8-9ee7-9b3c8b648167",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "519f08eb-913e-4e6e-8ace-105e5233dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a51792-76ad-4c29-9a15-059e383eb41c",
   "metadata": {},
   "source": [
    "### Function to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24119514-e06e-4026-9f9e-05df5d28647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_data(filename):\n",
    "    raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "    raw_text = raw_text.lower()\n",
    "    return raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61b4ee-6f63-4cac-9420-d4aa9eb9066f",
   "metadata": {},
   "source": [
    "### Function to Map Chars to Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f46de28-3df8-4155-a4f1-16d0e1f23f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_chars_to_int(raw_text):\n",
    "    # create mapping of unique chars to integers\n",
    "    chars = sorted(list(set(raw_text)))\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "    int_to_char = dict((i, c) for c, i in char_to_int.items())\n",
    "\n",
    "    n_chars = len(raw_text)\n",
    "    vocab_length = len(chars)\n",
    "    print(\"Total Characters: \", n_chars)\n",
    "    print(\"Vocab len: \", vocab_length)\n",
    "    \n",
    "    return chars, char_to_int, int_to_char, vocab_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3087cb93-5173-4b1e-8524-1d5288cb2119",
   "metadata": {},
   "source": [
    "### Function to window over data (currently unused)\n",
    "to create training data and labels  \n",
    "with specified sequence (input) window length and horizon (output) len\n",
    "\n",
    "only works with numbers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71aa40e6-c4b6-4e31-8bb4-f6c081528035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to label windowed data\n",
    "def get_labelled_windows(x, horizon=1):\n",
    "    \"\"\"\n",
    "    Creates labels for windowed dataset.\n",
    "    \n",
    "    E.g. if horizon=1 (default)\n",
    "    Input: [1, 2, 3, 4, 5, 6] -> Output: ([1, 2, 3, 4, 5], [6])\n",
    "    \"\"\"\n",
    "    return x[:, :-horizon], x[:, -horizon:]\n",
    "\n",
    "\n",
    "def make_windows(x, window_size, horizon = 1):\n",
    "    \"\"\"\n",
    "    Turns a 1D array into a 2D array of sequential windows of window_size.\n",
    "    \"\"\"\n",
    "    # 1. Create a window of specific window_size (add the horizon on the end for later labelling)\n",
    "    window_step = np.expand_dims(np.arange(window_size+horizon), axis=0)\n",
    "    # print(f\"Window step:\\n {window_step}\")\n",
    "    \n",
    "    # 2. Create a 2D array of multiple window steps (minus 1 to account for 0 indexing)\n",
    "    window_indexes = window_step + np.expand_dims(np.arange(len(x)-(window_size+horizon-1)), axis=0).T # create 2D array of windows of size window_size\n",
    "    # print(f\"Window indexes:\\n {window_indexes[:3], window_indexes[-3:], window_indexes.shape}\")\n",
    "    \n",
    "    # 3. Index on the target array (time series) with 2D array of multiple window steps\n",
    "    windowed_array = x[window_indexes]\n",
    "    \n",
    "    # 4. Get the labelled windows\n",
    "    windows, labels = get_labelled_windows(windowed_array, horizon=horizon)\n",
    "    \n",
    "    return windows, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a3aaed-9836-41a5-bb88-ec9c4227310b",
   "metadata": {},
   "source": [
    "### Function to window over chars and convert chars to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43d5f079-c740-4cfc-a81a-e07086dc647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chars_to_numbers_X_Y(raw_data, chars, char_to_int, window_size, horizon):\n",
    "def chars_to_numbers_X_Y_1(raw_data, chars, char_to_int, window_size):\n",
    "    n_chars = len(raw_data)\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(0, n_chars - window_size, 1):\n",
    "        seq_in = raw_text[i:i + window_size]\n",
    "        # seq_out = raw_text[i + window_size: i + window_size + horizon]\n",
    "        seq_out = raw_text[i+seq_length]\n",
    "        dataX.append([char_to_int[char] for char in seq_in])\n",
    "        # dataY.append([char_to_int[char] for char in seq_out])\n",
    "        dataY.append(char_to_int[seq_out])\n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c856239-e85b-44a9-999a-d5ac6975b5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chars, char_to_int, int_to_char, vocab_length = map_chars_to_int(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "754f421c-0af4-416a-8451-494b949b9ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataX, dataY = chars_to_numbers_X_Y(raw_text, chars, char_to_int, seq_length, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5979be53-f247-4e9b-b53a-185a03f477de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_X = len(dataX)\n",
    "# len_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a863bb3b-d370-4d31-b603-c358df8c326b",
   "metadata": {},
   "source": [
    "### Function to reshape data for training and turn into tensors\n",
    "reshape X to be [number_of_sequences, length_of_sentence, num_of_features] where:  \n",
    "number_of_seq.. = amount of samples generated  \n",
    "length_of_sentence also known as time steps = seq_length  \n",
    "num_of_features = output len, 1 character or more  \n",
    "\n",
    "plus normalization of data by vocab_length - total number of distinct characters - **necesarry or not?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9273509b-b8eb-4c15-bcb6-31b005260598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_train_data(x, y, window_size, horizon, device, vocab_length):\n",
    "    n_seq = len(x)\n",
    "    X = torch.tensor(x, dtype=torch.float32).reshape(n_seq, window_size, horizon).to(device)\n",
    "    X = X / float(vocab_length)\n",
    "    y = torch.tensor(y).to(device)\n",
    "    y = y.squeeze()\n",
    "    print(X.shape, y.shape)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c85311ac-00c6-4b22-9ade-af062f8d8ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = reshape_train_data(dataX, dataY, seq_length, horizon, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad9937d-496e-46fd-a5ca-c7e31d42c060",
   "metadata": {},
   "source": [
    "### Function to define LSTM-only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f664feaa-9386-46fb-b4e5-82a859b75f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LSTM_model(vocab_length, input_size=1, hidden_size=256, num_layers=2, dropout_perc=0.2, batch_first=True):\n",
    "    \"\"\"\n",
    "    we pass in vocab_length, to define linear after LSTM output range, because that's the number of possible characters\n",
    "    the network output could be\n",
    "    \"\"\"\n",
    "    class CharModel(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.lstm = nn.LSTM(input_size=input_size,\n",
    "                                hidden_size=hidden_size,\n",
    "                                num_layers=num_layers,\n",
    "                                batch_first=batch_first,\n",
    "                                dropout=dropout_perc)\n",
    "            self.dropout = nn.Dropout(dropout_perc)\n",
    "            self.linear = nn.Linear(hidden_size, vocab_length)\n",
    "        def forward(self, x):\n",
    "            x, _ = self.lstm(x)\n",
    "            # take only the last output\n",
    "            x = x[:, -1, :]\n",
    "            # produce output\n",
    "            x = self.linear(self.dropout(x))\n",
    "            return x\n",
    "    model = CharModel()\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b59eca5-c49e-4cc6-a6d1-599d864c881c",
   "metadata": {},
   "source": [
    "### Define traning optimalizer, loss function, data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a413a534-6ac5-4b8b-b6dc-7c1ce5774635",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_1 \u001b[38;5;241m=\u001b[39m create_LSTM_model(\u001b[43mvocab_length\u001b[49m, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model_1\u001b[38;5;241m.\u001b[39mparameters())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab_length' is not defined"
     ]
    }
   ],
   "source": [
    "# model_1 = create_LSTM_model(vocab_length, hidden_size=500, num_layers=3)\n",
    "# #\n",
    "# optimizer = optim.Adam(model_1.parameters())\n",
    "# loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "# #\n",
    "# loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X, y), shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a947df4-760c-418c-88d5-6027db2ce09b",
   "metadata": {},
   "source": [
    "### Function to train model\n",
    "and save the best model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b682aec9-1fa4-468d-96e7-8e46a3cb5973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, loss_fn, loader, file_name, epochs, char_to_int, int_to_char):\n",
    "    \"\"\"\n",
    "    char_to_int / char mappign saved along with model\n",
    "    \"\"\"\n",
    "    best_model = None\n",
    "    best_loss = np.inf\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in loader:\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        loss = 0\n",
    "        with torch.inference_mode():\n",
    "            for X_batch, y_batch in loader:\n",
    "                y_pred = model(X_batch)\n",
    "                loss += loss_fn(y_pred, y_batch)\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_model = model.state_dict()\n",
    "            print(\"Epoch %d: Cross-entropy: %.4f\" % (epoch, loss))\n",
    "    return best_model\n",
    "    torch.save([best_model, char_to_int, int_to_char], f\"{file_name}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3420a7-4b7c-4191-8761-091274217cb0",
   "metadata": {},
   "source": [
    "### Function to evaluate the model / make example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4095db-d90f-436a-bc22-6cd0204d99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_raw_line(raw_text, seq_length, char_to_int):\n",
    "    start = np.random.randint(0, len(raw_text)-seq_length)\n",
    "    prompt = raw_text[start:start+seq_length]\n",
    "    print(f\"Chosen prompt: {prompt}\")\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32fcd68-0d38-4353-9db0-656b636c9720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(prompt, model, char_to_int, int_to_char, vocab_length, output_length = 250):\n",
    "    \"\"\"\n",
    "    vocab_length for normalization\n",
    "    \"\"\"\n",
    "    pattern = [char_to_int[c] for c in prompt]\n",
    "    print('Prompt: \"%s\"' % prompt)\n",
    "    with torch.inference_mode():\n",
    "        for i in range(output_length):\n",
    "            # format input array of int into PyTorch tensor\n",
    "            x = np.reshape(pattern, (1, len(pattern), 1)) / float(vocab_length)\n",
    "            x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "            # generate logits as output from the model\n",
    "            prediction = model(x)\n",
    "            # convert logits into one character\n",
    "            index = int(prediction.argmax())\n",
    "            result = int_to_char[index]\n",
    "            print(result, end=\"\")\n",
    "            # append the new character into the prompt for the next iteration\n",
    "            pattern.append(index)\n",
    "            pattern = pattern[1:]\n",
    "    print()\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6106d479-fa32-4497-88e7-79bef3c0c321",
   "metadata": {},
   "source": [
    "### function to load model from state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11298972-d2b0-4a03-8f8c-a84be16ae26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_model(filename):\n",
    "#     best_model, char_to_int, int_to_char = torch.load(filename)\n",
    "# # reload the model\n",
    "# class CharModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.lstm = nn.LSTM(input_size=1, hidden_size=256, num_layers=1, batch_first=True)\n",
    "#         self.dropout = nn.Dropout(0.2)\n",
    "#         self.linear = nn.Linear(256, n_vocab)\n",
    "#     def forward(self, x):\n",
    "#         x, _ = self.lstm(x)\n",
    "#         # take only the last output\n",
    "#         x = x[:, -1, :]\n",
    "#         # produce output\n",
    "#         x = self.linear(self.dropout(x))\n",
    "#         return x\n",
    "# model = CharModel()\n",
    "# model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4980f5a-eb2c-4c31-972b-255b11cc3e27",
   "metadata": {},
   "source": [
    "## Basic function usage (for char-by-char LSTM and raw data start point):\n",
    "1. raw_text = load_text_data(filename)\n",
    "2. chars, char_to_int, int_to_char, vocab_length = map_chars_to_int(raw_text)\n",
    "3. dataX, dataY = chars_to_numbers_X_Y(raw_data, chars, char_to_int, window_size, horizon) ... or chars_to_number_X_Y_1 for horizon of 1 (default for now)\n",
    "4. X, y = reshape_train_data(x, y, window_size, horizon, device, vocab_length)\n",
    "5. model = create_LSTM_model(vocab_length, input_size=1, hidden_size=256, num_layers=2, dropout_perc=0.2, batch_first=True)\n",
    "6. best_model = train_model(model, optimizer, loss_fn, loader, file_name, epochs, char_to_int, int_to_char)\n",
    "7. prompt = get_random_raw_line(raw_text, seq_length, char_to_int)\n",
    "8. eval_model(prompt, model, char_to_int, int_to_char, vocab_length, output_length = 250)\n",
    "\n",
    "where:\n",
    "* filename - path to file with raw text data\n",
    "* window_size = seq_length - length of input the model will be trained to predict based on\n",
    "* horizon = input_size - the length of its output (one character, many characters, words etc) \n",
    "* device - \"cuda\" or \"cpu\"\n",
    "* optimizer = Adam etc\n",
    "* lossfn = crossentrophy etc\n",
    "* char_to_int, int_to_char - mapping functions\n",
    "* output_length - predicted eval text length\n",
    "* epochs - tranign epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04ff0f2-87f0-4dbc-98e3-26c51bee0ae7",
   "metadata": {},
   "source": [
    "### Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdbbcb9-03c0-4ad6-816c-0c03b5561aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "# filename = \"mfdoom_100.txt\"\n",
    "filename = \"doom_lyrics_10.txt\"\n",
    "\n",
    "# input window\n",
    "window_size = 100 #seq_length\n",
    "# output window / predicted\n",
    "horizon = 1\n",
    "\n",
    "# --------- training -----------\n",
    "# torch device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#\n",
    "n_epochs = 10\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e739e0-cef0-441f-9d63-e2552ba265fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = load_text_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4502f882-4ef9-4c17-abb5-c098c294e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars, char_to_int, int_to_char, vocab_length = map_chars_to_int(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c185bd7-8950-424a-9960-951312028509",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX, dataY = chars_to_numbers_X_Y_1(raw_text, chars, char_to_int, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310c482-86ac-4175-a395-ff80ff442501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataX[:5]\n",
    "len(dataX)\n",
    "dataY[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba70648-57e2-468d-a968-14138c811b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = reshape_train_data(dataX, dataY, window_size, horizon, device, vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df605b3-e57d-4777-86ce-ea75470fafc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7460e03-fd84-4ce8-999d-61b05c82f710",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_doom_big = create_LSTM_model(vocab_length, hidden_size=256, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00b597-962c-4e60-bd55-f028a21a2a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model_1.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X, y), shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181dc09-9bb2-4de8-bf4f-229941b3b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff854db-d2f6-45ac-b776-4dcd2859423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_doom_big = train_model(model_doom_big, optimizer, loss_fn, loader, \"best_model_doom_big\", n_epochs, char_to_int, int_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9729b3-d7a5-416f-8517-413474a5f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = get_random_raw_line(raw_text, window_size, char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a07a98-25c8-4f7c-acb8-ed19a077dca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(prompt = prompt,\n",
    "           model = model_doom_big,\n",
    "           char_to_int = char_to_int,\n",
    "           int_to_char = int_to_char,\n",
    "           vocab_length = vocab_length,\n",
    "           output_length = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5945dff-39ee-4d4f-9fe5-506866d8ad8e",
   "metadata": {},
   "source": [
    "### TODO: function chars_to_numbers_X_Y for now only works with horizon = 1, fix that"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "nlp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
